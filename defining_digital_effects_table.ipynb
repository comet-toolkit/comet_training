{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comet-toolkit/comet_training/blob/main/defining_digital_effects_table.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q--XLoo4Z325"
      },
      "source": [
        "Defining digital effects tables\n",
        "================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pxZ7fqqZ6jS"
      },
      "source": [
        "In this notebook, we will show how to create a digital effects table with obsarray (which can be propagated through a measurement function using punpy). \n",
        "First, we show how obsarray can be used as a templater for efficiently making xarray datasets (both with and without uncertainties). We show how, using obsarray's special variable types (uncertainties and flags), datasets including detailed uncertainty and covariance information as well as quality flags can be created.\n",
        "Finally, we define an example for a digital effects table quantifying the uncertainties and error-correlation of the gas temperature, pressure and amount of substance (number of moles). Using such a dataset, the uncertainties can be efficiently and easily propagated through a measurement function using punpy (see [this notebook](https://colab.research.google.com/github/comet-toolkit/comet_training/blob/master/training/punpy_digital_effects_table_example.ipynb))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzrTVRTqaNE3"
      },
      "source": [
        "We first install and import the obsarray package (and xarray):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install obsarray>=1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import obsarray\n",
        "import xarray as xr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Obsarray as a templater\n",
        "================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**obsarray** can create :py:class:`xarray.Dataset`'s to a particular templates, defined as a :py:class:`dict`'s (referred to hereafter as **template** dictionaries), which can range from very simple to more complex. Every key in the **template** dictionary is the name of a variable, with the corresponding entry a further variable specification dictionary (referred to hereafter as **variable** dictionaries).\n",
        "\n",
        "So a **template** dictionary may look something like this:\n",
        "\n",
        "template = {\n",
        "        \"temperature\": temperature_variable,\n",
        "        \"u_temperature\": u_temperature_variable\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each **variable** dictionary defines the following entries:\n",
        "\n",
        "* ``dim`` - list of variable dimension names.\n",
        "* ``dtype`` - variable data type, generally a :py:class:`numpy.dtype`, though for some :ref:`special variables <special variables>` particular values may be required.\n",
        "* ``attributes`` - dictionary of variable metadata, for some :ref:`special variables <special variables>` particular entries may be required.\n",
        "* ``encoding`` - (optional) variable `encoding <http://xarray.pydata.org/en/stable/user-guide/io.html?highlight=encoding#writing-encoded-data>`_.\n",
        "\n",
        "So for the previous example we may define:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "temperature_variable = {\n",
        "    \"dim\": [\"lon\", \"lat\", \"time\"],\n",
        "    \"dtype\": np.float32,\n",
        "    \"attributes\": {\"units\": \"K\", \"unc_comps\": [\"u_temperature\"]}\n",
        "}\n",
        "\n",
        "u_temperature_variable = {\n",
        "    \"dim\": [\"lon\", \"lat\", \"time\"],\n",
        "    \"dtype\": np.float16,\n",
        "    \"attributes\": {\"units\": \"%\"}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = {\n",
        "        \"temperature\": temperature_variable,\n",
        "        \"u_temperature\": u_temperature_variable\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following section details the special variable types that can be defined with **obsarray**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWb_xvSoaa6Y"
      },
      "source": [
        "Special variable types\n",
        "------------------------\n",
        "\n",
        "**obsarray**'s special variables allow the quick definition of a set of standardised variable formats. The following special variable types are available.\n",
        "\n",
        "Uncertainties\n",
        "_____________\n",
        "\n",
        "[Recent work](https://www.mdpi.com/2072-4292/11/5/474/htm) in the Earth Observation metrology domain is working towards the standardisation of the representation of measurement uncertainty information in data, with a particular focus on capturing the error-covariance associated with the uncertainty. Although it is typically the case that for large measurement datasets storing full error-covariance matrices is impractical, often the error-covariance between measurements may be efficiently parameterised. Work to standardise such parameterisations is on-going (see for example the EU H2020 FIDUCEO project defintions list in Appendix A of [this project report](https://ec.europa.eu/research/participants/documents/downloadPublic?documentIds=080166e5c84c9e2c&appId=PPGMS)).\n",
        "\n",
        "**dsbuilder** enables the specification of such error-correlation parameterisations for uncertainty variables through the variable attributes. This is achieved by including an ``\"err_corr\"`` list entry in a variable's **variable_spec** dictionary. Each element of ``err_corr`` is a  dictionary defining the error-correlation along one or more dimensions, which should include the following entries:\n",
        "\n",
        "* ``dim`` (*str*/*list*) - name of the dimension(s) as a str or list of str's (i.e. from ``dim_names``)\n",
        "* ``form`` (*str*) - error-correlation form, defines functional form of error-correlation structure along\n",
        "  dimension. Suggested error-correlation forms are defined in the table below.\n",
        "* ``params`` (*list*) - (optional) parameters of the error-correlation structure defining function for dimension\n",
        "  if required. The number of parameters required depends on the particular form.\n",
        "* ``units`` (*list*) - (optional) units of the error-correlation function parameters for dimension\n",
        "  (ordered as the parameters)\n",
        "\n",
        "Measurement variables with uncertainties should include a list of ``unc_comps`` in their attributes, as in the above example.\n",
        "\n",
        "An example ``err_corr`` dictionary may therefore look like:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "err_corr = [\n",
        "        {\n",
        "            \"dim\": \"x\",\n",
        "            \"form\": \"err_corr_matrix\",\n",
        "            \"params\": \"err_corr_var_x\",\n",
        "            \"units\": []\n",
        "        },\n",
        "        {\n",
        "            \"dim\": \"y\",\n",
        "            \"form\": \"random\",\n",
        "            \"params\": [],\n",
        "            \"units\": []\n",
        "        }\n",
        "]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the error-correlation structure is not defined along a particular dimension (i.e. it is not included in ``err_corr``), the error-correlation is assumed random. Variable attributes are populated to the effect of this assumption.\n",
        "\n",
        "| Form Name | Parameters | Description |\n",
        "| --- | --- | --- |\n",
        "| ``\"random\"`` | None required | Errors uncorrelated along dimension(s) |\n",
        "| ``\"systematic\"`` | None required | Errors fully correlated along dimension(s) |\n",
        "| ``\"err_corr_matrix\"`` | Error-correlation matrix variable name | Error-correlation for dimension(s) not parameterised, defined as a full matrix in another named variable in dataset. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Flags\n",
        "_____\n",
        "\n",
        "Setting the ``\"flag\"`` dtype builds a variable in the [cf conventions flag format](https://cfconventions.org/Data/cf-conventions/cf-conventions-1.8/cf-conventions.html#flags). Each datum bit corresponds to boolean condition flag with a given meaning.\n",
        "\n",
        "The variable must be defined with an attribute that lists the per bit flag meanings as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables = {\n",
        "       \"quality_flag\": {\n",
        "           \"dim\": [\"x\", \"y\"],\n",
        "           \"dtype\": \"flag\",\n",
        "           \"attributes\": {\n",
        "               \"flag_meanings\": [\"good_data\", \"bad_data\"]\n",
        "           }\n",
        "       }\n",
        "   }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The smallest necessary integer is used as the flag variable :py:class:`numpy.dtype`, given the number of flag meanings defined (i.e. 7 flag meanings results in an 8 bit integer variable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a template dataset\n",
        "----------------------------\n",
        "\n",
        "With the ``template`` dictionary prepared, only two more specifications are required to build a template dataset. First a dictionary that defines the sizes of all the dimensions used in the ``template`` dictionary, e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dim_size= {\"lon\":100, \"lat\":50, \"time\": 10}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Secondly, a dictionary of dataset global metadata, e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadata = {\"dataset_name\": \"my cool image\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combining the above together a template dataset can be created as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = obsarray.create_ds(\n",
        "       template,\n",
        "       dim_size,\n",
        "       metadata\n",
        "   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Where ``ds`` is an empty xarray dataset with variables defined by the template definition. Fill values for the empty arrays are chosen using the [cf convention values](http://cfconventions.org/cf-conventions/cf-conventions.html#missing-data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Populating and writing the dataset\n",
        "------------------------------------\n",
        "\n",
        "[Populating](http://xarray.pydata.org/en/stable/user-guide/data-structures.html#dictionary-like-methods) and [writing](http://xarray.pydata.org/en/stable/user-guide/io.html#reading-and-writing-files) the dataset can be achieved using xarray's builtin functionality. Here's a dummy example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ds\\[\"band_red\"] = ... # populate variable with red image array\n",
        "\n",
        "ds\\[\"band_green\"] = ... # populate variable with green image array\n",
        "\n",
        "ds\\[\"band_blue\"] = ... # populate variable with blue image array\n",
        "\n",
        "ds.to_netcdf(\"path/to/file.nc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining the example digital effects table\n",
        "==========================================\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we provide a full example of creating a digital effects table. The example is for a dataset quantifying the uncertainties and error-correlation of the gas temperature, pressure and amount of substance (number of moles) to be used in the calculation of the volume through the ideal gas law (see [this notebook](https://colab.research.google.com/github/comet-toolkit/comet_training/blob/master/training/punpy_digital_effects_table_example.ipynb)). Uncertainty propagation becomes very straightforward with punpy, once this digital effects table has been defined:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import obsarray\n",
        "\n",
        "# define ds variables\n",
        "template = {\n",
        "    \"temperature\": {\n",
        "        \"dtype\": np.float32,\n",
        "        \"dim\": [\"x\", \"y\", \"time\"],\n",
        "        \"attributes\": {\n",
        "            \"units\": \"K\",\n",
        "            \"unc_comps\": [\"u_ran_temperature\",\"u_sys_temperature\"]\n",
        "        }\n",
        "    },\n",
        "    \"u_ran_temperature\": {\n",
        "        \"dtype\": np.float32,\n",
        "        \"dim\": [\"x\", \"y\", \"time\"],\n",
        "        \"attributes\": {\n",
        "            \"units\": \"K\",\n",
        "            \"err_corr\": [\n",
        "              {\n",
        "                  \"dim\": \"x\",\n",
        "                  \"form\": \"random\",\n",
        "                  \"params\": [],\n",
        "                  \"units\": []\n",
        "              },\n",
        "              {\n",
        "                  \"dim\": \"y\",\n",
        "                  \"form\": \"random\",\n",
        "                  \"params\": [],\n",
        "                  \"units\": []\n",
        "              },\n",
        "              {\n",
        "                  \"dim\": \"time\",\n",
        "                  \"form\": \"random\",\n",
        "                  \"params\": [],\n",
        "                  \"units\": []\n",
        "              }\n",
        "          ]\n",
        "        },\n",
        "    },\n",
        "    \"u_sys_temperature\": {\n",
        "        \"dtype\": np.float32,\n",
        "        \"dim\": [\"x\", \"y\", \"time\"],\n",
        "        \"attributes\": {\n",
        "            \"units\": \"K\",\n",
        "            \"err_corr\": [\n",
        "              {\n",
        "                  \"dim\": \"x\",\n",
        "                  \"form\": \"systematic\",\n",
        "                  \"params\": [],\n",
        "                  \"units\": []\n",
        "              },\n",
        "              {\n",
        "                  \"dim\": \"y\",\n",
        "                  \"form\": \"systematic\",\n",
        "                  \"params\": [],\n",
        "                  \"units\": []\n",
        "              },\n",
        "              {\n",
        "                  \"dim\": \"time\",\n",
        "                  \"form\": \"systematic\",\n",
        "                  \"params\": [],\n",
        "                  \"units\": []\n",
        "              }\n",
        "          ]\n",
        "        }\n",
        "    },\n",
        "    \"pressure\": {\n",
        "        \"dtype\": np.float32,\n",
        "        \"dim\": [\"x\", \"y\", \"time\"],\n",
        "        \"attributes\": {\n",
        "            \"units\": \"Pa\",\n",
        "            \"unc_comps\": [\"u_str_pressure\"]\n",
        "        }\n",
        "    },\n",
        "    \"u_str_pressure\": {\n",
        "        \"dtype\": np.float32,\n",
        "        \"dim\": [\"x\", \"y\", \"time\"],\n",
        "        \"attributes\": {\n",
        "            \"units\": \"Pa\",\n",
        "            \"err_corr\": [\n",
        "              {\n",
        "                  \"dim\": \"x\",\n",
        "                  \"form\": \"random\",\n",
        "                  \"params\": [],\n",
        "                  \"units\": []\n",
        "              },\n",
        "              {\n",
        "                  \"dim\": \"y\",\n",
        "                  \"form\": \"err_corr_matrix\",\n",
        "                  \"params\": \"err_corr_str_pressure_y\",\n",
        "                  \"units\": []\n",
        "              },\n",
        "              {\n",
        "                  \"dim\": \"time\",\n",
        "                  \"form\": \"systematic\",\n",
        "                  \"params\": [],\n",
        "                  \"units\": []\n",
        "              }\n",
        "          ]\n",
        "        },\n",
        "    },\n",
        "    \"err_corr_str_pressure_y\": {\n",
        "        \"dtype\": np.float32,\n",
        "        \"dim\": [\"y\", \"y\"],\n",
        "        \"attributes\": {\"units\": \"\"},\n",
        "    },\n",
        "    \"n_moles\": {\n",
        "        \"dtype\": np.float32,\n",
        "        \"dim\": [\"x\", \"y\", \"time\"],\n",
        "        \"attributes\": {\n",
        "            \"units\": \"\",\n",
        "            \"unc_comps\": [\"u_ran_n_moles\"]\n",
        "        }\n",
        "    },\n",
        "    \"u_ran_n_moles\": {\n",
        "        \"dtype\": np.float32,\n",
        "        \"dim\": [\"x\", \"y\", \"time\"],\n",
        "        \"attributes\": {\n",
        "            \"units\": \"\",\n",
        "            \"err_corr\": [\n",
        "              {\n",
        "                  \"dim\": \"x\",\n",
        "                  \"form\": \"random\",\n",
        "                  \"params\": [],\n",
        "                  \"units\": []\n",
        "              },\n",
        "              {\n",
        "                  \"dim\": \"y\",\n",
        "                  \"form\": \"random\",\n",
        "                  \"params\": [],\n",
        "                  \"units\": []\n",
        "              },\n",
        "              {\n",
        "                  \"dim\": \"time\",\n",
        "                  \"form\": \"random\",\n",
        "                  \"params\": [],\n",
        "                  \"units\": []\n",
        "              }\n",
        "          ]\n",
        "       },  \n",
        "    },\n",
        "}\n",
        "\n",
        "# define dim_size_dict to specify size of arrays\n",
        "dim_sizes = {\n",
        "    \"x\": 20,\n",
        "    \"y\": 30,\n",
        "    \"time\": 6\n",
        "}\n",
        "\n",
        "# create dataset template\n",
        "ds = obsarray.create_ds(template, dim_sizes)\n",
        "\n",
        "# populate with example data\n",
        "ds[\"temperature\"].values = 293*np.ones((20,30,6))\n",
        "ds[\"u_ran_temperature\"].values = 1*np.ones((20,30,6))\n",
        "ds[\"u_sys_temperature\"].values = 0.4*np.ones((20,30,6))\n",
        "ds[\"pressure\"].values = 10**5*np.ones((20,30,6))\n",
        "ds[\"u_str_pressure\"].values = 10*np.ones((20,30,6))\n",
        "ds[\"err_corr_str_pressure_y\"].values = 0.5*np.ones((30,30))+0.5*np.eye(30)\n",
        "ds[\"n_moles\"].values = 40*np.ones((20,30,6))\n",
        "ds[\"u_ran_n_moles\"].values = 1*np.ones((20,30,6))\n",
        "\n",
        "# store example file\n",
        "# ds.to_netcdf(\"path/to/file.nc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here the last line has been commented as we do not want to save the NetCDF file as part of this notebook."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then inspect some of the results using the obsarray uncertainty accessor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(ds.unc[\"temperature\"].total_unc())\n",
        "print(ds.unc[\"pressure\"][\"u_str_pressure\"].value)\n",
        "print(ds.unc[\"pressure\"][\"u_str_pressure\"].err_corr)\n",
        "print(ds.unc[\"pressure\"][0,:,:][\"u_str_pressure\"].err_corr_matrix())  # here the [0,:,:] slice indicates we want the error correlation matrix of the second and third dimension"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM40nBwQDY7evd+aKCRtcm/",
      "include_colab_link": true,
      "name": "defining_digital_effects_table.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.2-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
