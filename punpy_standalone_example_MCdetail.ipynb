{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comet-toolkit/comet_training/blob/main/punpy_standalone_example_MCdetail.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pxZ7fqqZ6jS"
      },
      "source": [
        "Examples on how to use the punpy package with MC method\n",
        "========================================================\n",
        "\n",
        "1D input quantities and measurand\n",
        "----------------------------------\n",
        "Imagine you are trying to calibrate some L0 data to L1 and you have:\n",
        "\n",
        "-  A measurement function that uses L0 data, gains, and a dark signal in 5 wavelength bands\n",
        "-  Random uncertainties and systematic uncertainties on the L0 data;\n",
        "-  Random and systematic uncertainties on the gains;\n",
        "-  Random uncertainties on the dark signal.s\n",
        "\n",
        "After defining the data, the resulting uncertainty budget can then be calculated with punpy using the MC methods as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install punpy>=0.43.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import punpy\n",
        "import numpy as np\n",
        "\n",
        "# your measurement function\n",
        "def calibrate(L0,gains,dark):\n",
        "   return (L0-dark)*gains\n",
        "\n",
        "# your data\n",
        "L0 = np.array([0.43,0.8,0.7,0.65,0.9])\n",
        "dark = np.array([0.05,0.03,0.04,0.05,0.06])\n",
        "gains = np.array([23,26,28,29,31])\n",
        "\n",
        "# your uncertainties\n",
        "L0_ur = L0*0.05  # 5% random uncertainty\n",
        "L0_us = np.ones(5)*0.03  # systematic uncertainty of 0.03 \n",
        "                           # (common between bands)\n",
        "gains_ur = np.array([0.5,0.7,0.6,0.4,0.1])  # random uncertainty\n",
        "gains_us = np.array([0.1,0.2,0.1,0.4,0.3])  # systematic uncertainty \n",
        "# (different for each band but fully correlated)\n",
        "dark_ur = np.array([0.01,0.002,0.006,0.002,0.015])  # random uncertainty\n",
        "\n",
        "prop=punpy.MCPropagation(10000)\n",
        "L1=calibrate(L0,gains,dark)\n",
        "L1_ur=prop.propagate_random(calibrate,[L0,gains,dark],\n",
        "      [L0_ur,gains_ur,dark_ur])\n",
        "L1_us=prop.propagate_systematic(calibrate,[L0,gains,dark],\n",
        "      [L0_us,gains_us,np.zeros(5)])\n",
        "L1_ut=(L1_ur**2+L1_us**2)**0.5\n",
        "L1_cov=punpy.convert_corr_to_cov(np.eye(len(L1_ur)),L1_ur)+\\\n",
        "         punpy.convert_corr_to_cov(np.ones((len(L1_us),len(L1_us))),L1_ur)\n",
        "\n",
        "print(L1)\n",
        "print(L1_ur)\n",
        "print(L1_us)\n",
        "print(L1_ut)\n",
        "print(L1_cov)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWb_xvSoaa6Y"
      },
      "source": [
        "We now have for each band the random uncertainties in L1, systematic uncertainties in L1, total uncertainty in L1 and the covariance matrix between bands.\n",
        "Here we have manually specified a diagonal correlation matrix (no correlation, np.eye) for the random component and a correlation matrix of ones (fully correlated, np.ones).\n",
        "It would also have been possible to use the keyword `return_corr` to get the measured correlation matrix. In the next example we use the `return_corr` keyword:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prop=punpy.MCPropagation(10000)\n",
        "L1=calibrate(L0,gains,dark)\n",
        "L1_ur,L1_corr_r=prop.propagate_random(calibrate,[L0,gains,dark],\n",
        "                  [L0_ur,gains_ur,dark_ur],return_corr=True)\n",
        "L1_us,L1_corr_s=prop.propagate_systematic(calibrate,[L0,gains,dark],\n",
        "                  [L0_us,gains_us,np.zeros(5)],return_corr=True)\n",
        "L1_ut=(L1_ur**2+L1_us**2)**0.5\n",
        "L1_cov=punpy.convert_corr_to_cov(L1_corr_r,L1_ur)+\\\n",
        "       punpy.convert_corr_to_cov(L1_corr_s,L1_ur)\n",
        "\n",
        "print(L1)\n",
        "print(L1_ur)\n",
        "print(L1_us)\n",
        "print(L1_ut)\n",
        "print(L1_cov)                                            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_td3OAXcUXT"
      },
      "source": [
        "This will give nearly the same results other than a small error due to MC noise.\n",
        "\n",
        "Next we give an example where we try out a measurement function with multiple outputs.\n",
        "In order to process a measurement function with multiple outputs, it is necessary to set the keyword `output_vars` to the number of outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your measurement function\n",
        "def calibrate_2output(L0,gains,dark):\n",
        "    return (L0-dark)*gains,(L0*gains-dark)\n",
        "\n",
        "\n",
        "prop=punpy.MCPropagation(10000)\n",
        "L1=calibrate_2output(L0,gains,dark)\n",
        "L1_ur,L1_corr_r,L1_corr_r_between=prop.propagate_random(\n",
        "                                  calibrate_2output,[L0,gains,dark],\n",
        "                                  [L0_ur,gains_ur,dark_ur],\n",
        "                                  return_corr=True,output_vars=2)\n",
        "L1_us,L1_corr_s,L1_corr_s_between=prop.propagate_systematic(\n",
        "                                  calibrate_2output,[L0,gains,dark],\n",
        "                                  [L0_us,gains_us,np.zeros(5)],\n",
        "                                  return_corr=True,output_vars=2)\n",
        "\n",
        "print(L1)\n",
        "print(L1_ur)\n",
        "print(L1_us)                 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzSUig-Tei-T"
      },
      "source": [
        "Due to the multiple vars, L1_ur now has the shape (2,5) so L1_ur\\[0] now has the same uncertainties as \n",
        "the previous example, L1_corr_r\\[0] is the same as L1_corr_r before. Analogously, L1_ur\\[1] and L1_corr_r\\[0]\n",
        "give the random uncertainty and correlation matrix for the second output of the measurand.\n",
        "There is now also a L1_corr_r_between which gives the correlation matrix between the two output variables \n",
        "of the measurment function (averaged over all wavelengths).\n",
        "\n",
        "In addition to propagating random (uncorrelated) and systematic (fully correlated) uncertainties \n",
        "it is also possible to propagate uncertainties associated with structured errors.\n",
        "If we know the covariance matrix for each of the input quantities, it is straigtforward to propagate these.\n",
        "In the below example we assume the L0 data and dark data to be uncorrelated (their covariance matrix is a, \n",
        "diagonal matrix) and gains to be a custom covariance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "L0_cov=punpy.convert_corr_to_cov(np.eye(len(L0_ur)),L0_ur)\n",
        "dark_cov=punpy.convert_corr_to_cov(np.eye(len(dark_ur)),dark_ur )\n",
        "gains_cov= np.array([[0.45,0.35,0.30,0.20,0.05],\n",
        "                    [0.35,0.57,0.32,0.30,0.07],\n",
        "                    [0.30,0.32,0.56,0.24,0.06],\n",
        "                    [0.20,0.30,0.24,0.44,0.04],\n",
        "                    [0.05,0.07,0.06,0.04,0.21]])\n",
        "\n",
        "\n",
        "prop=punpy.MCPropagation(10000)\n",
        "L1=calibrate(L0,gains,dark)\n",
        "L1_ut,L1_corr=prop.propagate_cov(calibrate,[L0,gains,dark],\n",
        "                                [L0_cov,gains_cov,dark_cov])\n",
        "L1_cov=punpy.convert_corr_to_cov(L1_corr,L1_ut)\n",
        "\n",
        "print(L1)\n",
        "print(L1_ut)\n",
        "print(L1_cov)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is also possible to include covariance between the input variables. E.g. consider an example similar to the first one but where \n",
        "now the dark signal also has systematic uncertainties, which are entirely correlated with the systematic uncertainties on the L0 data \n",
        "(quite commonly the same detector is used for dark and L0). After defining this correlation matrix between the systematic uncertainties \n",
        "on the input variables, the resulting uncertainty budget can then be calculated with punpy as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# correlation matrix between the input variables:\n",
        "corr_input_syst=np.array([[1,0,1],[0,1,0],[1,0,1]])  # Here the correlation is\n",
        "# between the first and the third variable, following the order of \n",
        "# the arguments in the measurement function\n",
        "\n",
        "prop=punpy.MCPropagation(10000)\n",
        "L1=calibrate(L0,gains,dark)\n",
        "L1_ur=prop.propagate_random(calibrate,[L0,gains,dark],\n",
        "                            [L0_ur,gains_ur,dark_ur])\n",
        "L1_us=prop.propagate_systematic(calibrate,[L0,gains,dark],\n",
        "        [L0_us,gains_us,dark_us],corr_between=corr_input_syst)\n",
        "\n",
        "print(L1)\n",
        "print(L1_ur)\n",
        "print(L1_us)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This gives us the random and systematic uncertainties, which can be combined to get the total uncertainty. \n",
        "\n",
        "Since within python it is possible to do array operation using arrays of any size (as long as shapes of different arrays match up), \n",
        "it is often possible to process all 10000 MCsteps in our example at the same time.\n",
        "For the measurand function we defined L0, gains and dark can be processed using (5,10000) arrays rather than the normal (5,1) arrays that were defined above.\n",
        "The returned measurand will now also be a (5,10000) array in our example.\n",
        "This makes the processing of the MC steps as efficient as possible. However, not every measurement function will allow to do this. For example, a radiative \n",
        "transfer model cannot process 10000 model inputs at the same time. In this case we can force punpy to process the MC steps one-by-one by setting `parallel_cores` to 1.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# your measurement function\n",
        "def calibrate_slow(L0,gains,dark):\n",
        "    y2=np.repeat((L0-dark)*gains,30000)\n",
        "    y2=y2+np.random.random(len(y2))\n",
        "    y2=y2.sort()\n",
        "    return (L0-dark)*gains\n",
        "\n",
        "prop=punpy.MCPropagation(1000,parallel_cores=1)\n",
        "L1=calibrate_slow(L0,gains,dark)\n",
        "t1=time.time()\n",
        "L1_ur = prop.propagate_random(calibrate_slow,[L0,gains,dark],\n",
        "                                [L0_ur,gains_ur,dark_ur])\n",
        "t2=time.time()\n",
        "L1_us = prop.propagate_systematic(calibrate_slow,[L0,gains,dark],\n",
        "                                    [L0_us,gains_us,np.zeros(5)])\n",
        "\n",
        "print(L1)\n",
        "print(L1_ur)\n",
        "print(L1_us)\n",
        "print(\"propogate_random took: \",t2-t1,\" s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To speed up this slow process, it is also possible to use parallel processing. E.g. if we wanted to do parallel processing using 4 cores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    prop=punpy.MCPropagation(1000,parallel_cores=6)\n",
        "    L1=calibrate_slow(L0,gains,dark)\n",
        "    t1=time.time()\n",
        "    L1_ur = prop.propagate_random(calibrate_slow,[L0,gains,dark],\n",
        "                                [L0_ur,gains_ur,dark_ur])\n",
        "    t2=time.time()\n",
        "    L1_us = prop.propagate_systematic(calibrate_slow,[L0,gains,dark],\n",
        "                                    [L0_us,gains_us,np.zeros(5)])\n",
        "    \n",
        "    print(L1)\n",
        "    print(L1_ur)\n",
        "    print(L1_us)\n",
        "    print(\"propogate_random took: \",t2-t1,\" s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By using 6 cores, Propagate_random should now be significantly faster than when processing them in serial (setting parallel_cores=1).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**punpy for data with more dimensions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9UXNYPKat5M"
      },
      "source": [
        "We can expand the previous example to showcase the processing of 2D input quantities.\n",
        "Often when taking L0 data, it is good practice to take more than a single set of data.\n",
        "Now we assume we have 10 repeated measurements of the L0 data, darks and gains and still the same measurement function as before,\n",
        "and random uncertainties on the L0, dark, and gains which all have the same (10,5) shape, and systematic uncertainties on the gains only (same shape).\n",
        "In this case, other than the input arrays, very little changes in the propagation method and the uncertainties could be propagates as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your data\n",
        "wavs = np.array([350,450,550,650,750])\n",
        "\n",
        "L0 = np.tile([0.43,0.8,0.7,0.65,0.9],(50,100,1)).T\n",
        "L0 = L0 + np.random.normal(0.0,0.05,L0.shape)\n",
        "\n",
        "dark = np.tile([0.05,0.03,0.04,0.05,0.06],(50,100,1)).T\n",
        "gains = np.tile([23,26,28,29,31],(50,100,1)).T\n",
        "\n",
        "# your uncertainties\n",
        "L0_ur = L0*0.05  # 5% random uncertainty\n",
        "L0_us = np.ones((5,100,50))*0.03  # systematic uncertainty of 0.03\n",
        "                         # (common between bands)\n",
        "\n",
        "gains_ur = np.tile(np.array([0.5,0.7,0.6,0.4,0.1]),(50,100,1)).T  # random uncertainty\n",
        "gains_us = np.tile(np.array([0.1,0.2,0.1,0.4,0.3]),(50,100,1)).T  # systematic uncertainty\n",
        "# (different for each band but fully correlated)\n",
        "dark_ur = np.tile(np.array([0.01,0.002,0.006,0.002,0.015]),(50,100,1)).T  # random uncertainty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prop=punpy.MCPropagation(1000,)\n",
        "L1=calibrate(L0,gains,dark)\n",
        "L1_ur=prop.propagate_random(calibrate,[L0,gains,dark],\n",
        "      [L0_ur,gains_ur,dark_ur],repeat_dims=[1])\n",
        "L1_us=prop.propagate_systematic(calibrate,[L0,gains,dark],\n",
        "      [L0_us,gains_us,None],repeat_dims=[1])\n",
        "L1_ut=(L1_ur**2+L1_us**2)**0.5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then define a new function to plot images of the relative uncertainties in each band:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_plots_L1_image(wavs,L1,L1_u=None,c_range=[0,0.1]):\n",
        "  fig, axs = plt.subplots(1,len(wavs),figsize=(20,5))\n",
        "  \n",
        "  for i,ax in enumerate(axs):\n",
        "    ax.set_xlabel(\"x_pix\")\n",
        "    ax.set_ylabel(\"y_pix\")\n",
        "    ax.set_title(\"%s nm rel uncertainties\"%(wavs[i]))\n",
        "    im_plot=ax.imshow(L1_u[i]/L1[i],vmin=c_range[0],vmax=c_range[1])\n",
        "\n",
        "  plt.colorbar(im_plot)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "make_plots_L1_image(wavs,L1,L1_ur)\n",
        "make_plots_L1_image(wavs,L1,L1_us)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For multidimensional input quantities, it is often the case that a certain correlation structure is known along one of the dimensions, and that the other dimensions are either completely independent (random) or fully correlated (systematic). For example below, we know the correlation structure for the systematic uncertainties on the gains wrt wavelength, and consider each of the measurements to be fully correlted wrt the spatial dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gains_corr=np.array([[1.,0.14123392,0.12198785,0.07234254,0.01968095],\n",
        " [0.14123392,1.,0.1350783,0.12524757,0.0095603 ],\n",
        " [0.12198785,0.1350783,1.,0.1041107,0.02890266],\n",
        " [0.07234254,0.12524757,0.1041107,1.,0.01041678],\n",
        " [0.01968095,0.0095603,0.02890266,0.01041678,1.]])\n",
        "\n",
        "L1_us,L1_us_corr=prop.propagate_systematic(calibrate,[L0,gains,dark],\n",
        "      [None,gains_us,None],repeat_dims=[1,2],corr_x=[None,gains_corr,None],return_corr=True)\n",
        "\n",
        "make_plots_L1_image(wavs,L1,L1_us)\n",
        "make_plots_L1(np.mean(L1,axis=(1,2)),L1_us=np.mean(L1_us,axis=(1,2)),L1_corr=L1_us_corr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, the returned correlation matrix is again wrt wavelength, and the correlation structure of the repeated measurements is the same as it was in the inputs. In the above example, the uncertainties on the L0 and darks are set to None, and are thus not included. However, it is possible to include these, even if they have a different correlation structure than the uncertainties on the gains. In the example below, we repeat the same, but now include systematic uncertainties on the L0, that are fully correlated. It can be seem in this case we can just set corr_x to None, in which case it will default to a full correlation (because we are using the propagate_systematic function). If we were using propagate_random, it would default to independent errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "L1_us,L1_us_corr=prop.propagate_systematic(calibrate,[L0,gains,dark],\n",
        "      [L0_us,gains_us,None],repeat_dims=[1,2],corr_x=[None,gains_corr,None],return_corr=True)\n",
        "\n",
        "make_plots_L1_image(wavs,L1,L1_us)\n",
        "make_plots_L1(np.mean(L1,axis=(1,2)),L1_us=np.mean(L1_us,axis=(1,2)),L1_corr=L1_us_corr)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM40nBwQDY7evd+aKCRtcm/",
      "include_colab_link": true,
      "name": "punpy_standalone_example_MCdetail.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
